{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 106809,
     "databundleVersionId": 13056355,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# This note book is the same code as main.py but in a jupyter notebook format for easier debugging and testing."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"  # Enable CPU fallback for MPS"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from data import NeuralDataset, collate_batch, load_h5py_file\n",
    "from evaluation import run_evaluate\n",
    "from models import CTCEncoder, ConformerCTC\n",
    "from training import Trainer, EarlyStopping"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DEVICE = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "ASCII_SIZE = 128  # ASCII 0..127\n",
    "BLANK_ID = 128         # 128 # CTC blank token id\n",
    "VOCAB_SIZE = ASCII_SIZE + 1  # output vocab size (including blank)\n",
    "FEATURE_LEN = 512\n",
    "\n",
    "# Neural region blocks (type_id, region_id) -> (start, end)\n",
    "BLOCKS = {\n",
    "    # (type_id, region_id): (start, end)  # end exclusive\n",
    "    (0, 0): (0,   64),    # TC ventral6v\n",
    "    (0, 1): (64,  128),   # TC area4\n",
    "    (0, 2): (128, 192),   # TC 55b\n",
    "    (0, 3): (192, 256),   # TC dorsal6v\n",
    "    (1, 0): (256, 320),   # SBP ventral6v\n",
    "    (1, 1): (320, 384),   # SBP area4\n",
    "    (1, 2): (384, 448),   # SBP 55b\n",
    "    (1, 3): (448, 512),   # SBP dorsal6v\n",
    "}\n",
    "debug = True\n",
    "train = False"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = \"./brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/\"\n",
    "\n",
    "folders = os.listdir(path)\n",
    "train_files = []\n",
    "val_files = []\n",
    "for i, files in enumerate(folders):\n",
    "    if files.startswith(\".\"):\n",
    "        continue\n",
    "    files = os.listdir(os.path.join(path, files))\n",
    "    for file in files:\n",
    "        if file.endswith(\"train.hdf5\"):\n",
    "            train_files.append(os.path.join(path, folders[i], file))\n",
    "        elif file.endswith(\"val.hdf5\"):\n",
    "            val_files.append(os.path.join(path, folders[i], file))\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "i = 0\n",
    "for file in tqdm(train_files, desc=\"Loading train files\"):\n",
    "    data = load_h5py_file(file)\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    train_df = pd.concat([train_df, temp_df], ignore_index=True)\n",
    "    if debug:\n",
    "        i += 1\n",
    "        if i >= 4:  # load only 4 files in debug mode\n",
    "            break\n",
    "\n",
    "val_df = pd.DataFrame()\n",
    "i = 0\n",
    "for file in tqdm(val_files, desc=\"Loading val files\"):\n",
    "    data = load_h5py_file(file)\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    val_df = pd.concat([val_df, temp_df], ignore_index=True)\n",
    "    if debug:\n",
    "        i += 1\n",
    "        if i >= 2:  # load only 2 files in debug mode\n",
    "            continue"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ------------------------ Dataset and Dataloader ------------------------\n",
    "train_dataset = NeuralDataset(train_df, blank_id=BLANK_ID)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_batch(b)\n",
    ")\n",
    "\n",
    "val_dataset = NeuralDataset(val_df, blank_id=BLANK_ID)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_batch(b)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ------------------------ Define Model ------------------------\n",
    "model = CTCEncoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    blank_id=BLANK_ID,\n",
    "    rnn_layers=2,\n",
    "    use_gru=True\n",
    ").to(DEVICE)\n",
    "\n",
    "# number of model parameters\n",
    "num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model has {num_params:,} total parameters.\")\n",
    "print(f\"Model has {num_trainable_params:,} trainable parameters.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=1e-3),\n",
    "    loss_fn=nn.CTCLoss(blank=BLANK_ID, reduction=\"mean\", zero_infinity=True),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=DEVICE,\n",
    "    epochs=1,\n",
    "    blank_id=BLANK_ID,\n",
    "    early_stop=EarlyStopping(patience=5, min_delta=1e-3, path=f\"./models/{model.__str__()}_best_model.pt\"),\n",
    "    sample_interval=5,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if train:\n",
    "    print(\"Starting training...\")\n",
    "    trainer.run()\n",
    "else:\n",
    "    model.load_state_dict(torch.load(f\"./models/{model.__str__()}_best_model.pt\", map_location=DEVICE))\n",
    "trainer.predict_sample()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_cer, test_wer = run_evaluate(model, val_loader, blank_id=BLANK_ID, device=DEVICE)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from load_data import load_h5py_file"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-23T13:23:25.310091Z",
     "iopub.execute_input": "2025-10-23T13:23:25.310392Z",
     "iopub.status.idle": "2025-10-23T13:23:25.315318Z",
     "shell.execute_reply.started": "2025-10-23T13:23:25.310371Z",
     "shell.execute_reply": "2025-10-23T13:23:25.314587Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-27T01:47:03.961868Z",
     "start_time": "2025-10-27T01:47:03.945836Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Device configuration\n",
    "# ---------------------------\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Vocab / constants\n",
    "# ---------------------------\n",
    "# Vocabulary: A-Z, a-z, space, period, comma, question mark, exclamation mark\n",
    "ASCII_SIZE = 128  # ASCII 0..127\n",
    "BLANK_ID = 128         # 128 # CTC blank token id\n",
    "VOCAB_SIZE = ASCII_SIZE + 1  # output vocab size (including blank)\n",
    "FEATURE_LEN = 512\n",
    "\n",
    "# Neural region blocks (type_id, region_id) -> (start, end)\n",
    "BLOCKS = {\n",
    "    # (type_id, region_id): (start, end)  # end exclusive\n",
    "    (0, 0): (0,   64),    # TC ventral6v\n",
    "    (0, 1): (64,  128),   # TC area4\n",
    "    (0, 2): (128, 192),   # TC 55b\n",
    "    (0, 3): (192, 256),   # TC dorsal6v\n",
    "    (1, 0): (256, 320),   # SBP ventral6v\n",
    "    (1, 1): (320, 384),   # SBP area4\n",
    "    (1, 2): (384, 448),   # SBP 55b\n",
    "    (1, 3): (448, 512),   # SBP dorsal6v\n",
    "}"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-23T13:06:15.854019Z",
     "iopub.execute_input": "2025-10-23T13:06:15.854249Z",
     "iopub.status.idle": "2025-10-23T13:06:15.930083Z",
     "shell.execute_reply.started": "2025-10-23T13:06:15.854227Z",
     "shell.execute_reply": "2025-10-23T13:06:15.929178Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-27T01:47:03.981560Z",
     "start_time": "2025-10-27T01:47:03.966012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "# ---- Load data ----\n",
    "path = \"./brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final/\"\n",
    "\n",
    "folders = os.listdir(path)\n",
    "train_files = []\n",
    "test_files = []\n",
    "val_files = []\n",
    "for i, files in enumerate(folders):\n",
    "    if files.startswith(\".\"):\n",
    "        continue\n",
    "    files = os.listdir(os.path.join(path, files))\n",
    "    for file in files:\n",
    "        if file.endswith(\"train.hdf5\"):\n",
    "            train_files.append(os.path.join(path, folders[i], file))\n",
    "        elif file.endswith(\"test.hdf5\"):\n",
    "            test_files.append(os.path.join(path, folders[i], file))\n",
    "        elif file.endswith(\"val.hdf5\"):\n",
    "            val_files.append(os.path.join(path, folders[i], file))\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "for file in tqdm(train_files, desc=\"Loading train files\"):\n",
    "    data = load_h5py_file(file)\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    train_df = pd.concat([train_df, temp_df], ignore_index=True)\n",
    "\n",
    "val_df = pd.DataFrame()\n",
    "for file in tqdm(val_files, desc=\"Loading val files\"):\n",
    "    data = load_h5py_file(file)\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    val_df = pd.concat([val_df, temp_df], ignore_index=True)\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "for file in tqdm(test_files, desc=\"Loading test files\"):\n",
    "    data = load_h5py_file(file)\n",
    "    temp_df = pd.DataFrame(data)\n",
    "    test_df = pd.concat([test_df, temp_df], ignore_index=True)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-23T13:06:15.930941Z",
     "iopub.execute_input": "2025-10-23T13:06:15.931227Z",
     "iopub.status.idle": "2025-10-23T13:11:58.063214Z",
     "shell.execute_reply.started": "2025-10-23T13:06:15.931199Z",
     "shell.execute_reply": "2025-10-23T13:11:58.062601Z"
    },
    "ExecuteTime": {
     "end_time": "2025-10-27T01:47:56.648782Z",
     "start_time": "2025-10-27T01:47:03.985557Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading train files:   0%|          | 0/45 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a4e274b19e74772af69613225019b89"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Loading val files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbd7d544a4954eb299bed8bdf6bf5c32"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Loading test files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5bf3cbcb07b2473bb8174affcf59f550"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": "# Defining dataset class and functions",
   "metadata": {}
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T01:48:07.021705Z",
     "start_time": "2025-10-27T01:48:03.499766Z"
    }
   },
   "cell_type": "code",
   "source": "from data import NeuralDataset, collate_batch, ids_to_text",
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset and DataLoader\n",
    "train_dataset = NeuralDataset(train_df, blank_id=BLANK_ID)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_batch(b)\n",
    ")\n",
    "\n",
    "val_dataset = NeuralDataset(val_df, blank_id=BLANK_ID)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_batch(b)\n",
    ")\n",
    "\n",
    "test_dataset = NeuralDataset(test_df, blank_id=BLANK_ID)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda b: collate_batch(b)\n",
    ")\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "x_pad, x_len, y_flat, y_len = batch\n",
    "print(x_pad.shape, x_len.shape, y_flat.shape, y_len.shape)  # (B, T_max, 512) (B,) (sumL,) (B,)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-23T13:11:58.074875Z",
     "iopub.execute_input": "2025-10-23T13:11:58.075094Z",
     "iopub.status.idle": "2025-10-23T13:11:58.234920Z",
     "shell.execute_reply.started": "2025-10-23T13:11:58.075071Z",
     "shell.execute_reply": "2025-10-23T13:11:58.234200Z"
    },
    "ExecuteTime": {
     "start_time": "2025-10-27T01:48:07.033656Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T01:49:00.065828Z",
     "start_time": "2025-10-27T01:46:57.834554Z"
    }
   },
   "cell_type": "code",
   "source": "from evaluation import greedy_decode, predict_sentence, evaluate",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of evaluation failed: Traceback (most recent call last):\n",
      "  File \"/Users/valentinlhermitte/opt/miniconda3/envs/BrainToText2025/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 283, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/Users/valentinlhermitte/opt/miniconda3/envs/BrainToText2025/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 508, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/Users/valentinlhermitte/opt/miniconda3/envs/BrainToText2025/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 405, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/Users/valentinlhermitte/opt/miniconda3/envs/BrainToText2025/lib/python3.12/site-packages/IPython/extensions/autoreload.py\", line 317, in update_function\n",
      "    setattr(old, name, getattr(new, name))\n",
      "ValueError: predict_sentence() requires a code object with 2 free vars, not 0\n",
      "]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": "# Model",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from models import CTCEncoder",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "model = CTCEncoder(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    blank_id=BLANK_ID,\n",
    ").to(DEVICE)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-10-23T13:33:32.965618Z",
     "iopub.execute_input": "2025-10-23T13:33:32.965889Z",
     "iopub.status.idle": "2025-10-23T13:33:32.998154Z",
     "shell.execute_reply.started": "2025-10-23T13:33:32.965869Z",
     "shell.execute_reply": "2025-10-23T13:33:32.997613Z"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Training",
   "metadata": {}
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from training import Trainer, EarlyStopping",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    optimizer=torch.optim.AdamW(model.parameters(), lr=1e-3, betas=(0.9, 0.98), weight_decay=1e-2),\n",
    "    loss_fn=nn.CTCLoss(blank=BLANK_ID, reduction=\"mean\", zero_infinity=True),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=DEVICE,\n",
    "    epochs=2,\n",
    "    blank_id=BLANK_ID,\n",
    "    early_stop=EarlyStopping(patience=5, min_delta=1e-3, path=\"./best_model.pt\"),\n",
    "    sample_interval=5,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.run()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T01:49:00.118386Z",
     "start_time": "2025-10-27T01:39:27.646208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Predict on a random sample from val set\n",
    "#model.load_state_dict(torch.load(\"./model/best_model.pt\", map_location=DEVICE))\n",
    "trainer.predict_sample()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random sample index: 847\n",
      "Selected index: 847\n",
      "Target: We've had our way of life.\n",
      "Predicted text: I.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ]
}
